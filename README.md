# Readme

## Краткое содержание

В финальный код вошли три модели - случайный лес из sklearn, бустинг над деревьями catboost и нейронная сеть на pytorch. Первая слаба (F1 = 0.941), вторая побила бенчмарки (F1 = 0.963), третья показала себя наилучшим образом (F1 = 0.967).

Обучал локально на GPU Nvidia GTX1070. Для воспроизведения нужны и python-библиотеки, и CUDA Toolkit.

Обучение моделей завернуто в скрипты, в готовом виде они лежат в директории ./models/.



## Данные и задача

Данные - текст, представленный в формате BERT-эмбеддингов и меток класса. Исходный текст недоступен из-за конфиденциальности данных. Размерность: 90847*770. Количество классов: 14

Данные очень сильно не сбалансированы: самый крупный класс 7 содержит 61078 точек, самый мелкий класс 2 - 90.

Раз признаки построены state-of-the-art методом и количество данных большое, сразу нацелимся на обучение сложной модели. Отбор признаков, если он и необходим, оставим за алгоритмами. Будем считать, что это качественные и предобработанные данные.

В качестве тестовой выборки возьмем 25% данных. Кросс-валидация проводится так же. Для обучения нейросети размер теста будет 5%, потому что не будем дообучать ее на всех данных.

На Kaggle указано, что метрика - **mean F1**, но это не так. Результат валидации не близок к **f1_score(y_test, y_hat, average='macro')** из sklearn. Целевая метрика - **weighted F1**, где веса пропорциональны размерам классов.

В такой постановке самым важным из всех является класс с самой большой мощностью. При пометке всего набора данных классом 7 получаем **weighted F1 = 0.845** и **mean F1 (=macro F1) = 0.067**.

## Выбор классификаторов

Я буду использовать три модели, строящие сложные решающие правила и подходящие для многоклассовой классификации.

* RandomForestClassifier, sklearn
* CatBoostClassifier, catboost
* PyTorch: [Dropout(p=0.3), nn.BatchNorm1d(770), nn.Linear(770, 1024), nn.ReLU(), nn.Linear(1024, 256), nn.ReLU(), nn.Linear(256, 14), nn.LogSoftmax()]


### Случайный лес

Распараллелен, приспособлен для задач с высокой размерностью, пригоден для мультиклассификации, не требует шкалирования признаков.

#### Параметры

* Количество деревьев *n_estimators*

  Отчасти защищает от переобучения за счет того, что количество классификаторов растет. Не влияет на результат после высокого порога. Поэтому фиксируем на 300.

* Веса классов
  Оставим сбалансированными в виду оптимизируемой метрики: большие классы более важны.

* Количество признаков в узле дерева *max_features*

  Влияет на некоррелированность деревьев леса между собой. Для классификации по умолчанию берется *sqrt(features)*.

* Максимальная глубина дерева *max_depth*

  Слишком большая глубина приводит к переобучению леса. Экспериментально я подобрал порог ~14, где переобучение прекращается. Проверим.

* Максимальное количество листьев в дереве *max_leaf_nodes*

  Из всех оставляет листья с максимальным относительным приростом gini. Более гибкий вариант max_depth.

* Минимум количество точек, необходимый для разбиения листа *min_samples_split*

  По смыслу похоже на *max_depth*. Взял за дефолт значение 3.

Много экспериментировал руками, чтобы не перебирать огромную сетку параметров. Возможно, при подробном переборе можно было найти куда лучший набор параметров.

### CatBoost
Быстро развивающийся вариант бустинга над деревьями. Можно запускать на GPU. Показывает отличные результаты на практике.

Функция потерь: MultiClass

Метрика: TotalF1 (то же самое, что weighted F1)

Для предотвращения переобучения берем тестовую выборку как eval_set. Среди всех итераций обучения возьмем модель с лучшим weighted F1 на тесте.

#### Параметры

* Максимальное количество предикторов *iterations*

  Чем больше индекс предиктора, тем меньше он корректирует решающее правило.

* Скорость обучения *learning_rate*
  Определяет величину шага по градиенту целевой функции.

* Сила регуляризации *l2_leaf_reg*

  Коэффициент перед регуляризатором в целевой функции. Уменьшает переобучение.

* Максимальная глубина дерева *depth*

  Влияет на скорость обучения, сложность и качество модели. Лучшее значение~ 5-6. Чем больше - тем сложнее предикторы.

* Интенсивность бэггинга *bagging_temperature*

  Регулирует уровень случайности при бэггинге. Чем больше - тем больше случайности при назначении объектам весов. От 0 до +infty. При 1 веса объектов сэмплируются из экспоненциального распределения.



## Сравнение моделей

Более детальные различия в классификации увидим, сопоставив confusion matrices, см model_comparison.ipynb TODO

Случайный лес даже при тонкой настройке не дал хорошей точности: F1=0.9464 на тестовой выборке и 0.94110 на leaderboard. Это сильно ниже бенчмарков, рассматривать его не будем.



## Как обучить и запустить

### Python dependencies

Создать virtualenv в последней версии anaconda с python 3.7, используя requirements.txt из репозитория.  TODO

```shell
conda env create -f requirements.txt TODO: проверить
conda activate <environment_name>
```

Дальнейшие вычисления нужно проводить, используя полученный virtualenv. Для вычисления на GPU нужны драйверы Nvidia + CUDA Toolkit. Установка pytorch также зависит от системы, оборудования и версии CUDA. Я использовал CUDA 10.0.13 на Windows.

### Воспроизведение обучения моделей

Обучение моделей с оптимальными параметрами производится запуском скрипта train_models. Обучение Catboost с указанными параметрами на Nvidia GTX 1070 занимает 2-3 минуты, нейросети - примерно так же.

### Загрузка уже обученных моделей

Лучшие модели случайного леса, catboost и нейросети лежат в *./models/* и загружаются скриптом *load_trained.py*. Самой точной из моделей является нейросеть c weighted F1 = 0.96779. Дальше можно использовать метод predict на новых тестовых данных.

